{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50a4e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "781b0d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 33 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Pronouns</th>\n",
       "      <th>UFL Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Socials</th>\n",
       "      <th>Year</th>\n",
       "      <th>Major</th>\n",
       "      <th>Other Orgs</th>\n",
       "      <th>Role (0=Big,1=Little)</th>\n",
       "      <th>Preferred Littles</th>\n",
       "      <th>...</th>\n",
       "      <th>Favorite Food</th>\n",
       "      <th>EarlyBird/NightOwl (0=Early,1=Night)</th>\n",
       "      <th>Extroversion (1-5)</th>\n",
       "      <th>Good Advice (1-5)</th>\n",
       "      <th>Plans Style (1-5)</th>\n",
       "      <th>Study Frequency (1-5)</th>\n",
       "      <th>Gym Frequency (1-5)</th>\n",
       "      <th>Spending Habits (1-5)</th>\n",
       "      <th>Friday Night</th>\n",
       "      <th>Additional Info (Optional)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taylor Jarvis</td>\n",
       "      <td>they/them</td>\n",
       "      <td>daniel910@ufl.edu</td>\n",
       "      <td>(673)774-0860</td>\n",
       "      <td>@jeffrey63</td>\n",
       "      <td>0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>VSO</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>I would literally eat anything</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>gaming all night</td>\n",
       "      <td>I love hanging out at Plaza of Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Corey Knox</td>\n",
       "      <td>she/her</td>\n",
       "      <td>gabriel680@ufl.edu</td>\n",
       "      <td>1713894873</td>\n",
       "      <td>@chris19</td>\n",
       "      <td>0</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>FSA</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>gaming all night</td>\n",
       "      <td>I love hanging out at Plaza of Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mark Reyes</td>\n",
       "      <td>they/them</td>\n",
       "      <td>julie359@ufl.edu</td>\n",
       "      <td>(044)445-6922x353</td>\n",
       "      <td>@tracy38</td>\n",
       "      <td>0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>VSO</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Greek/Mediterranean</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>gaming all night</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kathleen Ballard</td>\n",
       "      <td>she/her</td>\n",
       "      <td>tara913@ufl.edu</td>\n",
       "      <td>119.318.8215</td>\n",
       "      <td>@james40</td>\n",
       "      <td>0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>AAA</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Greek/Mediterranean</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>gaming all night</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dawn Coleman</td>\n",
       "      <td>they/them</td>\n",
       "      <td>angela816@ufl.edu</td>\n",
       "      <td>931-155-4194x903</td>\n",
       "      <td>@joseph45</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>HSA</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>American</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>dinner with friends</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name   Pronouns           UFL Email              Phone  \\\n",
       "0     Taylor Jarvis  they/them   daniel910@ufl.edu      (673)774-0860   \n",
       "1        Corey Knox    she/her  gabriel680@ufl.edu         1713894873   \n",
       "2        Mark Reyes  they/them    julie359@ufl.edu  (044)445-6922x353   \n",
       "3  Kathleen Ballard    she/her     tara913@ufl.edu       119.318.8215   \n",
       "4      Dawn Coleman  they/them   angela816@ufl.edu   931-155-4194x903   \n",
       "\n",
       "      Socials  Year                   Major Other Orgs  Role (0=Big,1=Little)  \\\n",
       "0  @jeffrey63     0                 Finance        VSO                      1   \n",
       "1    @chris19     0  Mechanical Engineering        FSA                      1   \n",
       "2    @tracy38     0        Computer Science        VSO                      1   \n",
       "3    @james40     0                 Finance        AAA                      1   \n",
       "4   @joseph45     0            Data Science        HSA                      1   \n",
       "\n",
       "   Preferred Littles  ...                   Favorite Food  \\\n",
       "0                NaN  ...  I would literally eat anything   \n",
       "1                NaN  ...                           Asian   \n",
       "2                NaN  ...             Greek/Mediterranean   \n",
       "3                NaN  ...             Greek/Mediterranean   \n",
       "4                NaN  ...                        American   \n",
       "\n",
       "  EarlyBird/NightOwl (0=Early,1=Night)  Extroversion (1-5)  Good Advice (1-5)  \\\n",
       "0                                    1                   4                  4   \n",
       "1                                    0                   3                  3   \n",
       "2                                    1                   3                  3   \n",
       "3                                    0                   4                  4   \n",
       "4                                    1                   2                  2   \n",
       "\n",
       "  Plans Style (1-5) Study Frequency (1-5) Gym Frequency (1-5)  \\\n",
       "0                 3                     3                   1   \n",
       "1                 3                     4                   2   \n",
       "2                 3                     3                   1   \n",
       "3                 1                     3                   1   \n",
       "4                 2                     4                   2   \n",
       "\n",
       "  Spending Habits (1-5)         Friday Night  \\\n",
       "0                     3     gaming all night   \n",
       "1                     2     gaming all night   \n",
       "2                     5     gaming all night   \n",
       "3                     2     gaming all night   \n",
       "4                     1  dinner with friends   \n",
       "\n",
       "                Additional Info (Optional)  \n",
       "0  I love hanging out at Plaza of Americas  \n",
       "1  I love hanging out at Plaza of Americas  \n",
       "2                                      NaN  \n",
       "3                                      NaN  \n",
       "4                                      NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../vso_ratataou_ace_mock_data.csv\")\n",
    "\n",
    "print(f\"There are {len(df.columns)} columns\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c2258be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'pronouns', 'ufl_email', 'phone', 'socials', 'year', 'major',\n",
       "       'other_orgs', 'role', 'preferred_littles', 'preferred_bigs',\n",
       "       'pairing_requests', 'on_off_campus', 'has_car', 'ideal_big_little',\n",
       "       'looking_for_ace', 'free_time', 'hobbies', 'favorite_artists_songs',\n",
       "       'dislikes', 'talk_for_hours_about', 'self_description', 'best_joke',\n",
       "       'favorite_food', 'earlybird_nightowl', 'extroversion', 'good_advice',\n",
       "       'plans_style', 'study_frequency', 'gym_frequency', 'spending_habits',\n",
       "       'friday_night', 'additional_info'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_map = {\n",
    "    'Name': 'name',\n",
    "    'Pronouns': 'pronouns',\n",
    "    'UFL Email': 'ufl_email',\n",
    "    'Phone': 'phone',\n",
    "    'Socials': 'socials',\n",
    "    'Year': 'year',\n",
    "    'Major': 'major',\n",
    "    'Other Orgs': 'other_orgs',\n",
    "    'Role (0=Big,1=Little)': 'role',\n",
    "    'Preferred Littles': 'preferred_littles',\n",
    "    'Preferred Bigs': 'preferred_bigs',\n",
    "    'Pairing Requests (Optional)': 'pairing_requests',\n",
    "    'On/Off Campus (0=On,1=Off)': 'on_off_campus',\n",
    "    'Has Car (0=No,1=Yes)': 'has_car',\n",
    "    'Ideal Big/Little': 'ideal_big_little',\n",
    "    'Looking For ACE': 'looking_for_ace',\n",
    "    'Free Time': 'free_time',\n",
    "    'Hobbies': 'hobbies',\n",
    "    'Favorite Artists/Songs': 'favorite_artists_songs',\n",
    "    'Icks': 'dislikes',\n",
    "    'Talk for Hours About': 'talk_for_hours_about',\n",
    "    'Self Description': 'self_description',\n",
    "    'Best Joke': 'best_joke',\n",
    "    'Favorite Food': 'favorite_food',\n",
    "    'EarlyBird/NightOwl (0=Early,1=Night)': 'earlybird_nightowl',\n",
    "    'Extroversion (1-5)': 'extroversion',\n",
    "    'Good Advice (1-5)': 'good_advice',\n",
    "    'Plans Style (1-5)': 'plans_style',\n",
    "    'Study Frequency (1-5)': 'study_frequency',\n",
    "    'Gym Frequency (1-5)': 'gym_frequency',\n",
    "    'Spending Habits (1-5)': 'spending_habits',\n",
    "    'Friday Night': 'friday_night',\n",
    "    'Additional Info (Optional)': 'additional_info'\n",
    "}\n",
    "df = df.rename(columns=rename_map)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be1d895d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nName\\nUFL_Email\\n\\n# Preference Filtering characteristics\\nhard:\\nBig/Little\\nDo Not Pair with\\n\\nsoft -- boost:\\nMajor\\nYear difference\\nOrg participation\\n\\n# Feature Engineering -> Sentence-BERT\\n## Text Features\\nFree Time \\nHobbies\\nSelf Description\\ndislikes\\nTalk for Hours About\\nFriday Night\\n\\n## Categorical Features -> Embedding_Layer / One Hot\\nMajor\\nEarlyBord/NightOwl\\n\\n## Numerial Features -> Normalized 0-1\\nExtroversion\\nGood Advice\\nPlans Style\\nStudy Frequency\\nGym Frequency\\nSpending Habits\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Name\n",
    "UFL_Email\n",
    "\n",
    "# Preference Filtering characteristics\n",
    "hard:\n",
    "Big/Little\n",
    "Do Not Pair with\n",
    "\n",
    "soft -- boost:\n",
    "Major\n",
    "Year difference\n",
    "Org participation\n",
    "\n",
    "# Feature Engineering -> Sentence-BERT\n",
    "## Text Features\n",
    "Free Time \n",
    "Hobbies\n",
    "Self Description\n",
    "dislikes\n",
    "Talk for Hours About\n",
    "Friday Night\n",
    "\n",
    "## Categorical Features -> Embedding_Layer / One Hot\n",
    "Major\n",
    "EarlyBord/NightOwl\n",
    "\n",
    "## Numerial Features -> Normalized 0-1\n",
    "Extroversion\n",
    "Good Advice\n",
    "Plans Style\n",
    "Study Frequency\n",
    "Gym Frequency\n",
    "Spending Habits\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a605abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Duplicate entries by ufl_email -- keeping the latest entry\n",
    "## Reoders dataframe by index, keep the last entry and drop everything else\n",
    "df_cleaned = df.sort_index().drop_duplicates(subset=[\"ufl_email\"], keep=\"last\")\n",
    "\n",
    "# Handling Empty Fields\n",
    "df_cleaned = df_cleaned.fillna(np.NaN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b9a21",
   "metadata": {},
   "source": [
    "# Normalizing Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45daa33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(dataframe: pd.DataFrame, columns: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize data to a 0-1 range\n",
    "\n",
    "    Args:\n",
    "        dataframe: a pandas DataFrame\n",
    "        columns: column names to be normalized\n",
    "\n",
    "    Return the dataframe with normalized columns\n",
    "    \"\"\"\n",
    "    \n",
    "    df_out = dataframe.copy() # could remove this to modify in-place\n",
    "    for col in columns:\n",
    "        xmin = df_out[col].min()\n",
    "        xmax = df_out[col].max()\n",
    "        df_out[col] = (df_out[col] - xmin) / (xmax - xmin)\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "### This is how we normalize data! OR We could use sklearn.preprocessing MinMaxScaler\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "141fd7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.666667\n",
       "1       0.333333\n",
       "2       0.333333\n",
       "3       0.666667\n",
       "4       0.000000\n",
       "          ...   \n",
       "1995    1.000000\n",
       "1996    1.000000\n",
       "1997    0.666667\n",
       "1998    0.333333\n",
       "1999    1.000000\n",
       "Name: extroversion, Length: 1987, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "columns_to_scale = ['extroversion', 'good_advice', 'plans_style', 'study_frequency', 'gym_frequency', 'spending_habits']\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_cleaned[columns_to_scale] = scaler.fit_transform(df_cleaned[columns_to_scale])\n",
    "\n",
    "df_cleaned['extroversion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b8bfd9",
   "metadata": {},
   "source": [
    "# Text Features -> One single Sentence-SBERT Embedding\n",
    "\n",
    "Why do we combine them into one single Embedding?\n",
    "1. Many embeddings leads to noisier signal, and larger dimensions to work with\n",
    "\n",
    "2. Multiple embedding lose cross context, where it only sees local patterns, and misses global patterns.\n",
    "\n",
    "3. SBERT is trained on semantic similarity, and large conherent text\n",
    "\n",
    "4. N text fields x 768  > 1 text field x 768 -- Model is faster with smaller embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac3fa0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       photography.traveling, music, movies.Ahead ten...\n",
       "1       photography.music, reading.Defense stage fall ...\n",
       "2       cooking.gaming.Seven hand across anything also...\n",
       "3       traveling.traveling, photography.Situation dri...\n",
       "4       cooking.gym, photography.Crime area strategy b...\n",
       "                              ...                        \n",
       "1995    gym.gym, movies, music.It explain response mat...\n",
       "1996    traveling.photography, traveling.Song hear exe...\n",
       "1997    movies.gaming.Often usually though fire succes...\n",
       "1998    movies.cooking, movies, photography.Range beha...\n",
       "1999    photography.traveling, reading, gaming.People ...\n",
       "Name: profile_text, Length: 1987, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_col_combine = ['free_time', 'hobbies', 'self_description', 'dislikes', 'talk_for_hours_about', 'friday_night', 'additional_info']\n",
    "\n",
    "# 1. For each column 2. fill NaN with an empty string 3. convert to str 4. join each row with comma as delimiter\n",
    "df_cleaned['profile_text'] = df_cleaned[text_col_combine].fillna('').astype(str).apply('.'.join, axis=1)\n",
    "df_cleaned['profile_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caaa7d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load a pre-trained Sentence model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "df_cleaned['profile_text'] = df_cleaned['profile_text'].astype(str)\n",
    "type(df_cleaned['profile_text'])\n",
    "model.predict(df_cleaned['profile_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353b78bd",
   "metadata": {},
   "source": [
    "# Categorical Features\n",
    "Categorical -> one-hot encode -> vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f69b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0cc111e",
   "metadata": {},
   "source": [
    "# Input Features\n",
    "profile_embedding: Semantic Embedding \n",
    "\n",
    "categorical_vector: Yes/No for Filtering\n",
    "\n",
    "numeric_vector: Normalized features on a StandardScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfbb606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Purpose:\n",
    "- Rename and clean columns\n",
    "- Building a profile_text (biography) from many columns\n",
    "- categorical encoding\n",
    "- normalize scaling\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Optional, Dict\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "import config\n",
    "\n",
    "class FeatureEngineer:\n",
    "    def __init__(\n",
    "            self,\n",
    "            profile_text: Optional[List[str]] = None,\n",
    "            categorical_fields: Optional[list[str]] = None,\n",
    "            numeric_fields: Optional[List[str]] = None\n",
    "    ):\n",
    "        self.profile_text = profile_text\n",
    "        self.categorical_fields = categorical_fields\n",
    "        self.numeric_fields = numeric_fields\n",
    "\n",
    "        # ColumnTransformer Fit\n",
    "        self.column_transformer: Optional[ColumnTransformer] = None\n",
    "        self.fitted = False\n",
    "    \n",
    "    @staticmethod\n",
    "    def rename_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Rename all columns in-place for the given column name map in config.py\n",
    "        \"\"\"\n",
    "        df = df.rename(columns=config.RENAME_MAP)\n",
    "        \n",
    "        # lower all columns \n",
    "        df.columns = [col.lower() for col in df.columns]\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_profile_text(df: pd.DataFrame, text_fields: List[str]) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Combine our profile_text fields together by checking cases for each row\n",
    "\n",
    "        Return:\n",
    "            A 1D array or pd.Series that includes our profile_text\n",
    "        \"\"\"\n",
    "        def join_row(row) -> str:\n",
    "            \"\"\"\n",
    "            Check each row for:\n",
    "                1. None values\n",
    "                2. NaN values \n",
    "                3. String Casting\n",
    "            Return: A Str\n",
    "            \"\"\"\n",
    "            parts = []\n",
    "            for field in text_fields:\n",
    "                # verify the field exist, else it's empty str\n",
    "                candidate_text = row.get(field, \"\")\n",
    "                # If NaN -> empty str\n",
    "                if pd.isna(candidate_text):\n",
    "                    candidate_text = \"\"\n",
    "\n",
    "                candidate_text = str(candidate_text).strip()\n",
    "                if candidate_text:\n",
    "                    parts.append(candidate_text)\n",
    "\n",
    "            if parts:\n",
    "                return \". \".join(parts)\n",
    "            else:\n",
    "                return \"\"\n",
    "        \n",
    "        return (df.apply(join_row, axis=1)) # Axis=1 : apply for each row at O(n) times\n",
    "\n",
    "    def _clean_table(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Remove NaN, normalize whitespace/trailing spaces & consistent string types\n",
    "\n",
    "        Return:\n",
    "            A new copy of cleaned DataFrame\n",
    "        \"\"\"\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        # Standardize all columns to str\n",
    "        for col in df_copy.columns:\n",
    "            # Fill empty fields with empty string + str cast\n",
    "            df_copy[col] = df_copy[col].fillna(\"\").astype(str)\n",
    "        \n",
    "        # Numeric coercion for numeric fields\n",
    "        for col in self.numeric_fields:\n",
    "            if col in df_copy.columns:\n",
    "                # Cast integer if possible, else NaN upon TypeError\n",
    "                df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce', downcast='float')\n",
    "                df_copy[col] = df_copy[col].fillna(0).astype(float)\n",
    "        return df_copy\n",
    "\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Performing preprocessing transformation on profile_text, categorical_fields, numeric_fields\n",
    "        where we transformed:\n",
    "            profile_text: : List[str]\n",
    "            categorical_fields: One Hot Encoding\n",
    "            numeric_field: Standard Scaler \n",
    "        \n",
    "        Output: \n",
    "            update column_transforemr with our given DataFrame with a single matrix\n",
    "        \"\"\"\n",
    "        print(\"Fitting DataFrame...\")\n",
    "\n",
    "        df = self.rename_column(df)\n",
    "        df = self._clean_table(df)\n",
    "        df['profile_text'] = self.build_profile_text(df, self.profile_text)\n",
    "        \n",
    "        # Building our ColumnTransformer through Onehot & StandardScaler\n",
    "        transformers = []\n",
    "\n",
    "        ##categorical_fields : One Hot Encoidng\n",
    "        available_category = [c for c in self.categorical_fields if c in df.columns]\n",
    "        if available_category:\n",
    "            ohe = OneHotEncoder(handle_unknown='error', sparse_output=False)\n",
    "            transformers.append((\"OneHot\" , ohe, available_category))\n",
    "\n",
    "        ## numeric_fields : StandardScaler | Mean=0, Var=1 \n",
    "        available_nums = [c for c in self.numeric_fields if c in df.columns]\n",
    "        if available_nums:\n",
    "            scaler = StandardScaler()\n",
    "            transformers.append(('likert_scale', scaler, available_nums))\n",
    "            \n",
    "        if not transformers:\n",
    "            raise ValueError(\"No categorical or numeric features available to fit ColumnTransformer.\")\n",
    "\n",
    "        self.column_transformer = ColumnTransformer(transformers=transformers, \n",
    "                                                    remainder='drop') # Drop other features not mentioned\n",
    "        x_meta = self.column_transformer.fit_transform(df)\n",
    "        self.fitted = True\n",
    "        print(\"Finished Fitting.\")\n",
    "        print(\"Fit Status: \", self.fitted)\n",
    "        return self\n",
    "\n",
    "    def transform(self, df: pd.DataFrame) -> Dict[str, np.ndarray]:\n",
    "        print(\"Transforming...\")\n",
    "\n",
    "        if not self.fitted or self.column_transformer is None:\n",
    "            raise RuntimeError(\"FeatureEngineer must be fitted before transform(). Call fit() first.\")\n",
    "\n",
    "        df = self.rename_column(df)\n",
    "        df = self._clean_table(df)\n",
    "        df['profile_text'] = self.build_profile_text(df, self.profile_text)\n",
    "        \n",
    "        print(\"Our current DataFrame\", df.head())\n",
    "\n",
    "        x_meta = self.column_transformer.transform(df)\n",
    "        # If OneHotEncoder is Sparse -> cast to dense | Empty fields are filled with zeros\n",
    "        if hasattr(x_meta, \"toarray\"):\n",
    "            x_meta = x_meta.toarray()\n",
    "        \n",
    "        print(\"Finished Transforming.\")\n",
    "        return {\n",
    "            'profile_text': df['profile_text'].tolist(),\n",
    "            'meta_features': x_meta,\n",
    "            'index': df.index.to_numpy(),\n",
    "            'raw_df': df\n",
    "        }\n",
    "    def fit_transform(self, df: pd.DataFrame) -> Dict[str, np.ndarray]:\n",
    "        self.fit(df)\n",
    "        return self.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b4aac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "testFeature = FeatureEngineer(\n",
    "    categorical_fields=config.DEFAULT_CATEGORICALS,\n",
    "    numeric_fields=config.DEFAULT_NUMERICS,\n",
    "    profile_text=config.DEFAULT_PROFILE_TEXT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0307f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting DataFrame...\n",
      "Finished Fitting.\n",
      "Fit Status:  True\n",
      "Transforming...\n",
      "Our current DataFrame                name   pronouns           ufl_email              phone  \\\n",
      "0     Taylor Jarvis  they/them   daniel910@ufl.edu      (673)774-0860   \n",
      "1        Corey Knox    she/her  gabriel680@ufl.edu         1713894873   \n",
      "2        Mark Reyes  they/them    julie359@ufl.edu  (044)445-6922x353   \n",
      "3  Kathleen Ballard    she/her     tara913@ufl.edu       119.318.8215   \n",
      "4      Dawn Coleman  they/them   angela816@ufl.edu   931-155-4194x903   \n",
      "\n",
      "      socials year                   major other_orgs role preferred_littles  \\\n",
      "0  @jeffrey63    0                 Finance        VSO    1                     \n",
      "1    @chris19    0  Mechanical Engineering        FSA    1                     \n",
      "2    @tracy38    0        Computer Science        VSO    1                     \n",
      "3    @james40    0                 Finance        AAA    1                     \n",
      "4   @joseph45    0            Data Science        HSA    1                     \n",
      "\n",
      "   ... earlybird_nightowl extroversion good_advice plans_style  \\\n",
      "0  ...                  1          4.0         4.0         3.0   \n",
      "1  ...                  0          3.0         3.0         3.0   \n",
      "2  ...                  1          3.0         3.0         3.0   \n",
      "3  ...                  0          4.0         4.0         1.0   \n",
      "4  ...                  1          2.0         2.0         2.0   \n",
      "\n",
      "  study_frequency gym_frequency spending_habits         friday_night  \\\n",
      "0             3.0           1.0             3.0     gaming all night   \n",
      "1             4.0           2.0             2.0     gaming all night   \n",
      "2             3.0           1.0             5.0     gaming all night   \n",
      "3             3.0           1.0             2.0     gaming all night   \n",
      "4             4.0           2.0             1.0  dinner with friends   \n",
      "\n",
      "                           additional_info  \\\n",
      "0  I love hanging out at Plaza of Americas   \n",
      "1  I love hanging out at Plaza of Americas   \n",
      "2                                            \n",
      "3                                            \n",
      "4                                            \n",
      "\n",
      "                                        profile_text  \n",
      "0  photography. traveling, music, movies. Ahead t...  \n",
      "1  photography. music, reading. Defense stage fal...  \n",
      "2  cooking. gaming. Seven hand across anything al...  \n",
      "3  traveling. traveling, photography. Situation d...  \n",
      "4  cooking. gym, photography. Crime area strategy...  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "Finished Transforming.\n"
     ]
    }
   ],
   "source": [
    "test = testFeature.fit_transform(df=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a8d7a7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ..., -0.42983946,\n",
       "        -1.39758469, -0.00945811],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.47129149,\n",
       "        -0.6936891 , -0.71005889],\n",
       "       [ 0.        ,  1.        ,  0.        , ..., -0.42983946,\n",
       "        -1.39758469,  1.39174345],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  1.37242243,\n",
       "         0.71410207,  0.69114267],\n",
       "       [ 0.        ,  0.        ,  1.        , ...,  0.47129149,\n",
       "        -1.39758469,  0.69114267],\n",
       "       [ 0.        ,  1.        ,  0.        , ..., -1.33097041,\n",
       "        -1.39758469,  0.69114267]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['meta_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7de5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gstatsmcmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
