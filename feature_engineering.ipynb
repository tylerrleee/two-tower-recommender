{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d2cf477a-70c8-482d-878f-5d7fa1f828d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01fa6363-25d1-4b21-a36f-24874a97916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = pd.read_csv(\"./vso_ratataou_ace_mock_data.csv\" ,encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d5dc6bf3-122f-4cb8-bd46-3c00d8bd0651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Pronouns</th>\n",
       "      <th>UFL Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Socials</th>\n",
       "      <th>Year</th>\n",
       "      <th>Major</th>\n",
       "      <th>Other Orgs</th>\n",
       "      <th>Role (0=Big,1=Little)</th>\n",
       "      <th>Preferred Littles</th>\n",
       "      <th>...</th>\n",
       "      <th>Favorite Food</th>\n",
       "      <th>EarlyBird/NightOwl (0=Early,1=Night)</th>\n",
       "      <th>Extroversion (1-5)</th>\n",
       "      <th>Good Advice (1-5)</th>\n",
       "      <th>Plans Style (1-5)</th>\n",
       "      <th>Study Frequency (1-5)</th>\n",
       "      <th>Gym Frequency (1-5)</th>\n",
       "      <th>Spending Habits (1-5)</th>\n",
       "      <th>Friday Night</th>\n",
       "      <th>Additional Info (Optional)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taylor Jarvis</td>\n",
       "      <td>they/them</td>\n",
       "      <td>daniel910@ufl.edu</td>\n",
       "      <td>(673)774-0860</td>\n",
       "      <td>@jeffrey63</td>\n",
       "      <td>0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>VSO</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>I would literally eat anything</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>gaming all night</td>\n",
       "      <td>I love hanging out at Plaza of Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Corey Knox</td>\n",
       "      <td>she/her</td>\n",
       "      <td>gabriel680@ufl.edu</td>\n",
       "      <td>1713894873</td>\n",
       "      <td>@chris19</td>\n",
       "      <td>0</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>FSA</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>gaming all night</td>\n",
       "      <td>I love hanging out at Plaza of Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mark Reyes</td>\n",
       "      <td>they/them</td>\n",
       "      <td>julie359@ufl.edu</td>\n",
       "      <td>(044)445-6922x353</td>\n",
       "      <td>@tracy38</td>\n",
       "      <td>0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>VSO</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Greek/Mediterranean</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>gaming all night</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kathleen Ballard</td>\n",
       "      <td>she/her</td>\n",
       "      <td>tara913@ufl.edu</td>\n",
       "      <td>119.318.8215</td>\n",
       "      <td>@james40</td>\n",
       "      <td>0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>AAA</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Greek/Mediterranean</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>gaming all night</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dawn Coleman</td>\n",
       "      <td>they/them</td>\n",
       "      <td>angela816@ufl.edu</td>\n",
       "      <td>931-155-4194x903</td>\n",
       "      <td>@joseph45</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>HSA</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>American</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>dinner with friends</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name   Pronouns           UFL Email              Phone  \\\n",
       "0     Taylor Jarvis  they/them   daniel910@ufl.edu      (673)774-0860   \n",
       "1        Corey Knox    she/her  gabriel680@ufl.edu         1713894873   \n",
       "2        Mark Reyes  they/them    julie359@ufl.edu  (044)445-6922x353   \n",
       "3  Kathleen Ballard    she/her     tara913@ufl.edu       119.318.8215   \n",
       "4      Dawn Coleman  they/them   angela816@ufl.edu   931-155-4194x903   \n",
       "\n",
       "      Socials  Year                   Major Other Orgs  Role (0=Big,1=Little)  \\\n",
       "0  @jeffrey63     0                 Finance        VSO                      1   \n",
       "1    @chris19     0  Mechanical Engineering        FSA                      1   \n",
       "2    @tracy38     0        Computer Science        VSO                      1   \n",
       "3    @james40     0                 Finance        AAA                      1   \n",
       "4   @joseph45     0            Data Science        HSA                      1   \n",
       "\n",
       "   Preferred Littles  ...                   Favorite Food  \\\n",
       "0                NaN  ...  I would literally eat anything   \n",
       "1                NaN  ...                           Asian   \n",
       "2                NaN  ...             Greek/Mediterranean   \n",
       "3                NaN  ...             Greek/Mediterranean   \n",
       "4                NaN  ...                        American   \n",
       "\n",
       "  EarlyBird/NightOwl (0=Early,1=Night)  Extroversion (1-5)  Good Advice (1-5)  \\\n",
       "0                                    1                   4                  4   \n",
       "1                                    0                   3                  3   \n",
       "2                                    1                   3                  3   \n",
       "3                                    0                   4                  4   \n",
       "4                                    1                   2                  2   \n",
       "\n",
       "  Plans Style (1-5) Study Frequency (1-5) Gym Frequency (1-5)  \\\n",
       "0                 3                     3                   1   \n",
       "1                 3                     4                   2   \n",
       "2                 3                     3                   1   \n",
       "3                 1                     3                   1   \n",
       "4                 2                     4                   2   \n",
       "\n",
       "  Spending Habits (1-5)         Friday Night  \\\n",
       "0                     3     gaming all night   \n",
       "1                     2     gaming all night   \n",
       "2                     5     gaming all night   \n",
       "3                     2     gaming all night   \n",
       "4                     1  dinner with friends   \n",
       "\n",
       "                Additional Info (Optional)  \n",
       "0  I love hanging out at Plaza of Americas  \n",
       "1  I love hanging out at Plaza of Americas  \n",
       "2                                      NaN  \n",
       "3                                      NaN  \n",
       "4                                      NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "631a3b55-d03b-49b3-8d51-0f2b815cb66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'Pronouns', 'UFL Email', 'Phone', 'Socials', 'Year', 'Major', 'Other Orgs', 'Role (0=Big,1=Little)', 'Preferred Littles', 'Preferred Bigs', 'Pairing Requests (Optional)', 'On/Off Campus (0=On,1=Off)', 'Has Car (0=No,1=Yes)', 'Ideal Big/Little', 'Looking For ACE', 'Free Time', 'Hobbies', 'Favorite Artists/Songs', 'Icks', 'Talk for Hours About', 'Self Description', 'Best Joke', 'Favorite Food', 'EarlyBird/NightOwl (0=Early,1=Night)', 'Extroversion (1-5)', 'Good Advice (1-5)', 'Plans Style (1-5)', 'Study Frequency (1-5)', 'Gym Frequency (1-5)', 'Spending Habits (1-5)', 'Friday Night', 'Additional Info (Optional)']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'self_description'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gstatsMCMC/lib/python3.12/site-packages/pandas/core/indexes/base.py:3791\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3790\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3791\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3792\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:152\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:181\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'self_description'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m column_names = \u001b[38;5;28mlist\u001b[39m(main_df.columns)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(column_names)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mmain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mself_description\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gstatsMCMC/lib/python3.12/site-packages/pandas/core/frame.py:3893\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3891\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   3892\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m3893\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3894\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   3895\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gstatsMCMC/lib/python3.12/site-packages/pandas/core/indexes/base.py:3798\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3793\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3794\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3795\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3796\u001b[39m     ):\n\u001b[32m   3797\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3798\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3799\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3800\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3801\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3802\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3803\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'self_description'"
     ]
    }
   ],
   "source": [
    "# Binary Encoding (0 or 1)\n",
    "main_df = pd.DataFrame(mock_data)\n",
    "column_names = list(main_df.columns)\n",
    "print(column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "db905745-ca89-42ff-bf79-c0ef43f515cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'pronouns', 'ufl_email', 'phone', 'socials', 'year', 'major',\n",
      "       'other_orgs', 'role_', 'preferred_littles', 'preferred_bigs',\n",
      "       'pairing_requests_', 'on_off_campus_', 'has_car_', 'ideal_big_little',\n",
      "       'looking_for_ace', 'free_time', 'hobbies', 'favorite_artists_songs',\n",
      "       'icks', 'talk_for_hours_about', 'self_description', 'best_joke',\n",
      "       'favorite_food', 'earlybird_nightowl_', 'extroversion_', 'good_advice_',\n",
      "       'plans_style_', 'study_frequency_', 'gym_frequency_',\n",
      "       'spending_habits_', 'friday_night', 'additional_info_'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def clean_column_name(col):\n",
    "    # Remove parentheses and their contents\n",
    "    col = re.sub(r\"\\(.*?\\)\", \"\", col)\n",
    "    # Replace spaces and slashes with underscores\n",
    "    col = col.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    # Convert to lowercase and strip leading/trailing underscores\n",
    "    return col.strip().lower()\n",
    "\n",
    "main_df.columns = [clean_column_name(col) for col in main_df.columns]\n",
    "print(binary_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "74c3fb99-df08-4b83-b2d4-276ce39444f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       0\n",
      "2       1\n",
      "3       1\n",
      "4       0\n",
      "       ..\n",
      "1995    0\n",
      "1996    1\n",
      "1997    1\n",
      "1998    0\n",
      "1999    0\n",
      "Name: on_off_campus_, Length: 2000, dtype: int64 0       0\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       0\n",
      "       ..\n",
      "1995    1\n",
      "1996    1\n",
      "1997    0\n",
      "1998    0\n",
      "1999    1\n",
      "Name: has_car_, Length: 2000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fitlering columns to convert\n",
    "\"\"\"\n",
    "binary_cols = ['on_off_campus_','has_car_']\n",
    "mapping = {'On-Campus': 1, 'Off-Campus': 0, 'Yes': 1, 'No': 0}\n",
    "for col in binary_cols:\n",
    "    binary_df[col] = binary_df[col].map(mapping)\n",
    "\"\"\"\n",
    "print(main_df['on_off_campus_'], main_df['has_car_'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "34213f7b-b726-490a-9237-a26cc713cf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name   pronouns            ufl_email                phone  \\\n",
      "0        Taylor Jarvis  they/them    daniel910@ufl.edu        (673)774-0860   \n",
      "1           Corey Knox    she/her   gabriel680@ufl.edu           1713894873   \n",
      "2           Mark Reyes  they/them     julie359@ufl.edu    (044)445-6922x353   \n",
      "3     Kathleen Ballard    she/her      tara913@ufl.edu         119.318.8215   \n",
      "4         Dawn Coleman  they/them    angela816@ufl.edu     931-155-4194x903   \n",
      "...                ...        ...                  ...                  ...   \n",
      "1995   Stephen Johnson     he/him  courtney615@ufl.edu   038.917.8624x41924   \n",
      "1996         Emma Hart    she/her  danielle955@ufl.edu           5664866850   \n",
      "1997      Gerald Davis  they/them     joshua18@ufl.edu  (254)065-5691x55108   \n",
      "1998  Taylor Dominguez    she/her    lauren547@ufl.edu   489.462.8788x88092   \n",
      "1999      Joseph Young    she/her    nathan675@ufl.edu   (893)438-4626x6667   \n",
      "\n",
      "         socials  year                   major other_orgs  role_  \\\n",
      "0     @jeffrey63     0                 Finance        VSO      1   \n",
      "1       @chris19     0  Mechanical Engineering        FSA      1   \n",
      "2       @tracy38     0        Computer Science        VSO      1   \n",
      "3       @james40     0                 Finance        AAA      1   \n",
      "4      @joseph45     0            Data Science        HSA      1   \n",
      "...          ...   ...                     ...        ...    ...   \n",
      "1995  @melissa32     1                 Biology        CSA      0   \n",
      "1996  @shannon39     2                 Biology        HSA      0   \n",
      "1997   @amanda41     2                 Finance        VSO      0   \n",
      "1998   @monica52     2            Data Science        AAA      0   \n",
      "1999  @cynthia89     1        Computer Science        CSA      0   \n",
      "\n",
      "      preferred_littles  ...  good_advice_ plans_style_  study_frequency_  \\\n",
      "0                   NaN  ...             4            3                 3   \n",
      "1                   NaN  ...             3            3                 4   \n",
      "2                   NaN  ...             3            3                 3   \n",
      "3                   NaN  ...             4            1                 3   \n",
      "4                   NaN  ...             2            2                 4   \n",
      "...                 ...  ...           ...          ...               ...   \n",
      "1995                4.0  ...             4            3                 4   \n",
      "1996                5.0  ...             3            3                 4   \n",
      "1997                5.0  ...             5            3                 5   \n",
      "1998                2.0  ...             3            3                 4   \n",
      "1999                3.0  ...             3            3                 2   \n",
      "\n",
      "      gym_frequency_ spending_habits_         friday_night  \\\n",
      "0                  1                3     gaming all night   \n",
      "1                  2                2     gaming all night   \n",
      "2                  1                5     gaming all night   \n",
      "3                  1                2     gaming all night   \n",
      "4                  2                1  dinner with friends   \n",
      "...              ...              ...                  ...   \n",
      "1995               2                3  dinner with friends   \n",
      "1996               2                1  studying at Marston   \n",
      "1997               4                4     gaming all night   \n",
      "1998               1                4       sleeping early   \n",
      "1999               1                4     gaming all night   \n",
      "\n",
      "                             additional_info_ year_0 year_1 year_2  \n",
      "0     I love hanging out at Plaza of Americas      1      0      0  \n",
      "1     I love hanging out at Plaza of Americas      1      0      0  \n",
      "2                                         NaN      1      0      0  \n",
      "3                                         NaN      1      0      0  \n",
      "4                                         NaN      1      0      0  \n",
      "...                                       ...    ...    ...    ...  \n",
      "1995                Looking for study buddies      0      1      0  \n",
      "1996  I love hanging out at Plaza of Americas      0      0      1  \n",
      "1997                                      NaN      0      0      1  \n",
      "1998                                      NaN      0      0      1  \n",
      "1999                                      NaN      0      1      0  \n",
      "\n",
      "[2000 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "## One Hot Encoding\n",
    "\"\"\"\n",
    " For categorical questions with a fixed number of mutually exclusive options (e.g., multiple choice)\n",
    " transforms a single column of categorical data into multiple new columns, one for each unique category. \n",
    " Each new column contains binary values (0 or 1) indicating the presence of that category\n",
    " Form Question Example: \n",
    "     What year are you? (Freshman, Sophomore, Junior, Senior)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Perform one hot encoding\n",
    "one_hot_encoded_df = pd.get_dummies(main_df['year'], prefix='year', dtype=int)\n",
    "\n",
    "main_df = main_df.join(one_hot_encoded_df)\n",
    "\n",
    "print(main_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "028dcee4-f4c2-42ff-aa54-b7dd6e14e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial import distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c87eb814-17ba-4134-a1ea-f1a90308a707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cooking   gaming       gym    movies     music  painting  photography  \\\n",
      "0     0.000000  0.00000  0.000000  0.577863  0.576323       0.0     0.000000   \n",
      "1     0.000000  0.00000  0.000000  0.000000  0.715089       0.0     0.000000   \n",
      "2     0.000000  1.00000  0.000000  0.000000  0.000000       0.0     0.000000   \n",
      "3     0.000000  0.00000  0.000000  0.000000  0.000000       0.0     0.713790   \n",
      "4     0.000000  0.00000  0.698139  0.000000  0.000000       0.0     0.715962   \n",
      "...        ...      ...       ...       ...       ...       ...          ...   \n",
      "1995  0.000000  0.00000  0.575472  0.579059  0.577515       0.0     0.000000   \n",
      "1996  0.000000  0.00000  0.000000  0.000000  0.000000       0.0     0.713790   \n",
      "1997  0.000000  1.00000  0.000000  0.000000  0.000000       0.0     0.000000   \n",
      "1998  0.580971  0.00000  0.000000  0.570040  0.000000       0.0     0.580971   \n",
      "1999  0.000000  0.59664  0.000000  0.000000  0.000000       0.0     0.000000   \n",
      "\n",
      "       reading  traveling  \n",
      "0     0.000000   0.577863  \n",
      "1     0.699033   0.000000  \n",
      "2     0.000000   0.000000  \n",
      "3     0.000000   0.700360  \n",
      "4     0.000000   0.000000  \n",
      "...        ...        ...  \n",
      "1995  0.000000   0.000000  \n",
      "1996  0.000000   0.700360  \n",
      "1997  0.000000   0.000000  \n",
      "1998  0.000000   0.000000  \n",
      "1999  0.560214   0.574614  \n",
      "\n",
      "[2000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "## TF-IDF Vectorization\n",
    "\"\"\"\n",
    "TLDR: Keyword focused\n",
    "When: Free-response where specific keywords are important for matching\n",
    "(e.g., shared hobbies, academic majors, favorite artists)\n",
    "\n",
    "What: Term Frequency-Inverse Document Frequency\n",
    "  statistical measure that evaluates how relevant a word is to a document in a collection of documents\n",
    "  more frequent more better\n",
    "'corpus' refers to the text-response\n",
    "\n",
    "Form Question Examples: \n",
    "    Major/Minor/Track, \n",
    "    What are your main hobbies and interests?, \n",
    "    Favorite genre(s)?\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Initialize vectorizer\n",
    "tfidf_vectorizer =  TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit vector into data & transform into matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(main_df['hobbies'])\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), \n",
    "                        columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(tfidf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "52d747d9-dd55-4b16-88e8-97607a80887f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Ahead ten civil theory fly ready skin against.\n",
       "1             Defense stage fall where his laugh mention.\n",
       "2            Seven hand across anything also bad it site.\n",
       "3       Situation drive they general involve risk stud...\n",
       "4       Crime area strategy bill physical American cou...\n",
       "                              ...                        \n",
       "1995    It explain response material apply begin estab...\n",
       "1996    Song hear executive ask answer production do t...\n",
       "1997    Often usually though fire successful pass mont...\n",
       "1998      Range behavior fall series party music officer.\n",
       "1999       People which security ground player we chance.\n",
       "Name: self_description, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# S-BERT Embedding\n",
    "\"\"\"\n",
    "TLDR: Semantic Meaning, Context focused\n",
    "When: Open-ended where SEMANTIC MEANING, CONTEXT & NUANCE matters more than keywords\n",
    "    Good for personality, goals & abstractons\n",
    "What: BERT model using embeddings for texts, measured by cosine similarity\n",
    "Form Question Examples: \n",
    "    How would you describe your ideal big/little?,\n",
    "    What are you looking for when signing up for ACE?, \n",
    "    Describe yourself in your own words!\n",
    "\"\"\"\n",
    "# Documentation: https://sbert.net/index.html\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "03e434cd-4358-4902-b64f-c896971b8d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of one embedding: (2000,)\n",
      "First embedding vector: 0       [-0.020410795, 0.04957276, 0.008686418, 0.0378...\n",
      "1       [0.0237088, 0.03708684, -0.03792438, -0.022004...\n",
      "2       [-0.0785125, -0.091397375, 0.008947419, 0.0064...\n",
      "3       [0.01942276, 0.0009503136, -0.001155221, 0.006...\n",
      "4       [-0.03206001, 0.048228964, -0.021651598, -0.02...\n",
      "                              ...                        \n",
      "1995    [-0.07386307, -0.0054821246, 0.03733131, 0.015...\n",
      "1996    [-0.040608127, 0.086723156, 0.056251753, -0.08...\n",
      "1997    [0.028389689, -0.055047974, -0.01629945, 0.023...\n",
      "1998    [-0.022966195, -0.016591884, 0.016417472, -0.0...\n",
      "1999    [-0.006967092, -0.01825596, -0.0497002, -0.069...\n",
      "Name: self_description_embedding, Length: 2000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Loading pretrained model\n",
    "# More Models https://sbert.net/docs/sentence_transformer/pretrained_models.html \n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Encode sentences to get their embeddings\n",
    "# output: list of np arrays (vectors)\n",
    "embeddings = model.encode(main_df['self_description'])\n",
    "\n",
    "# Embeddings as a new column\n",
    "main_df['self_description_embedding'] = list(embeddings)\n",
    "\n",
    "print(\"Shape of one embedding:\", main_df['self_description_embedding'].shape)\n",
    "print(\"First embedding vector:\", main_df['self_description_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63364114-f0e8-41f2-8a2a-572e10e0a14f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
