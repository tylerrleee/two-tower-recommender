{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9938e2b4-89a8-4031-87c5-3307844ca4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Feature Groups for Mentors/Mentees\n",
    "# Adding features by embedding data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2cf477a-70c8-482d-878f-5d7fa1f828d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01fa6363-25d1-4b21-a36f-24874a97916d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './vso_ratataou_ace_mock_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m mock_data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./vso_ratataou_ace_mock_data.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gstatsMCMC/lib/python3.12/site-packages/pandas/io/parsers/readers.py:948\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    935\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    936\u001b[39m     dialect,\n\u001b[32m    937\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    944\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    945\u001b[39m )\n\u001b[32m    946\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m948\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gstatsMCMC/lib/python3.12/site-packages/pandas/io/parsers/readers.py:611\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    608\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    610\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    614\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gstatsMCMC/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1448\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1445\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1447\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gstatsMCMC/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1705\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1703\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1704\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1705\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1707\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1710\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1712\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1713\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1714\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1716\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/gstatsMCMC/lib/python3.12/site-packages/pandas/io/common.py:872\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    863\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    864\u001b[39m             handle,\n\u001b[32m    865\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    868\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    869\u001b[39m         )\n\u001b[32m    870\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    871\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m872\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    873\u001b[39m     handles.append(handle)\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './vso_ratataou_ace_mock_data.csv'"
     ]
    }
   ],
   "source": [
    "mock_data = pd.read_csv(\"./vso_ratataou_ace_mock_data.csv\" ,encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5dc6bf3-122f-4cb8-bd46-3c00d8bd0651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Pronouns</th>\n",
       "      <th>UFL Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Socials</th>\n",
       "      <th>Year</th>\n",
       "      <th>Major</th>\n",
       "      <th>Other Orgs</th>\n",
       "      <th>Role (0=Big,1=Little)</th>\n",
       "      <th>Preferred Littles</th>\n",
       "      <th>...</th>\n",
       "      <th>Favorite Food</th>\n",
       "      <th>EarlyBird/NightOwl (0=Early,1=Night)</th>\n",
       "      <th>Extroversion (1-5)</th>\n",
       "      <th>Good Advice (1-5)</th>\n",
       "      <th>Plans Style (1-5)</th>\n",
       "      <th>Study Frequency (1-5)</th>\n",
       "      <th>Gym Frequency (1-5)</th>\n",
       "      <th>Spending Habits (1-5)</th>\n",
       "      <th>Friday Night</th>\n",
       "      <th>Additional Info (Optional)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taylor Jarvis</td>\n",
       "      <td>they/them</td>\n",
       "      <td>daniel910@ufl.edu</td>\n",
       "      <td>(673)774-0860</td>\n",
       "      <td>@jeffrey63</td>\n",
       "      <td>0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>VSO</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>I would literally eat anything</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>gaming all night</td>\n",
       "      <td>I love hanging out at Plaza of Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Corey Knox</td>\n",
       "      <td>she/her</td>\n",
       "      <td>gabriel680@ufl.edu</td>\n",
       "      <td>1713894873</td>\n",
       "      <td>@chris19</td>\n",
       "      <td>0</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>FSA</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>gaming all night</td>\n",
       "      <td>I love hanging out at Plaza of Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mark Reyes</td>\n",
       "      <td>they/them</td>\n",
       "      <td>julie359@ufl.edu</td>\n",
       "      <td>(044)445-6922x353</td>\n",
       "      <td>@tracy38</td>\n",
       "      <td>0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>VSO</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Greek/Mediterranean</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>gaming all night</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kathleen Ballard</td>\n",
       "      <td>she/her</td>\n",
       "      <td>tara913@ufl.edu</td>\n",
       "      <td>119.318.8215</td>\n",
       "      <td>@james40</td>\n",
       "      <td>0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>AAA</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Greek/Mediterranean</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>gaming all night</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dawn Coleman</td>\n",
       "      <td>they/them</td>\n",
       "      <td>angela816@ufl.edu</td>\n",
       "      <td>931-155-4194x903</td>\n",
       "      <td>@joseph45</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>HSA</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>American</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>dinner with friends</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name   Pronouns           UFL Email              Phone  \\\n",
       "0     Taylor Jarvis  they/them   daniel910@ufl.edu      (673)774-0860   \n",
       "1        Corey Knox    she/her  gabriel680@ufl.edu         1713894873   \n",
       "2        Mark Reyes  they/them    julie359@ufl.edu  (044)445-6922x353   \n",
       "3  Kathleen Ballard    she/her     tara913@ufl.edu       119.318.8215   \n",
       "4      Dawn Coleman  they/them   angela816@ufl.edu   931-155-4194x903   \n",
       "\n",
       "      Socials  Year                   Major Other Orgs  Role (0=Big,1=Little)  \\\n",
       "0  @jeffrey63     0                 Finance        VSO                      1   \n",
       "1    @chris19     0  Mechanical Engineering        FSA                      1   \n",
       "2    @tracy38     0        Computer Science        VSO                      1   \n",
       "3    @james40     0                 Finance        AAA                      1   \n",
       "4   @joseph45     0            Data Science        HSA                      1   \n",
       "\n",
       "   Preferred Littles  ...                   Favorite Food  \\\n",
       "0                NaN  ...  I would literally eat anything   \n",
       "1                NaN  ...                           Asian   \n",
       "2                NaN  ...             Greek/Mediterranean   \n",
       "3                NaN  ...             Greek/Mediterranean   \n",
       "4                NaN  ...                        American   \n",
       "\n",
       "  EarlyBird/NightOwl (0=Early,1=Night)  Extroversion (1-5)  Good Advice (1-5)  \\\n",
       "0                                    1                   4                  4   \n",
       "1                                    0                   3                  3   \n",
       "2                                    1                   3                  3   \n",
       "3                                    0                   4                  4   \n",
       "4                                    1                   2                  2   \n",
       "\n",
       "  Plans Style (1-5) Study Frequency (1-5) Gym Frequency (1-5)  \\\n",
       "0                 3                     3                   1   \n",
       "1                 3                     4                   2   \n",
       "2                 3                     3                   1   \n",
       "3                 1                     3                   1   \n",
       "4                 2                     4                   2   \n",
       "\n",
       "  Spending Habits (1-5)         Friday Night  \\\n",
       "0                     3     gaming all night   \n",
       "1                     2     gaming all night   \n",
       "2                     5     gaming all night   \n",
       "3                     2     gaming all night   \n",
       "4                     1  dinner with friends   \n",
       "\n",
       "                Additional Info (Optional)  \n",
       "0  I love hanging out at Plaza of Americas  \n",
       "1  I love hanging out at Plaza of Americas  \n",
       "2                                      NaN  \n",
       "3                                      NaN  \n",
       "4                                      NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "631a3b55-d03b-49b3-8d51-0f2b815cb66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'Pronouns', 'UFL Email', 'Phone', 'Socials', 'Year', 'Major', 'Other Orgs', 'Role (0=Big,1=Little)', 'Preferred Littles', 'Preferred Bigs', 'Pairing Requests (Optional)', 'On/Off Campus (0=On,1=Off)', 'Has Car (0=No,1=Yes)', 'Ideal Big/Little', 'Looking For ACE', 'Free Time', 'Hobbies', 'Favorite Artists/Songs', 'Icks', 'Talk for Hours About', 'Self Description', 'Best Joke', 'Favorite Food', 'EarlyBird/NightOwl (0=Early,1=Night)', 'Extroversion (1-5)', 'Good Advice (1-5)', 'Plans Style (1-5)', 'Study Frequency (1-5)', 'Gym Frequency (1-5)', 'Spending Habits (1-5)', 'Friday Night', 'Additional Info (Optional)']\n"
     ]
    }
   ],
   "source": [
    "# Binary Encoding (0 or 1)\n",
    "main_df = pd.DataFrame(mock_data)\n",
    "column_names = list(main_df.columns)\n",
    "print(column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db905745-ca89-42ff-bf79-c0ef43f515cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'pronouns', 'ufl_email', 'phone', 'socials', 'year', 'major',\n",
      "       'other_orgs', 'role_', 'preferred_littles', 'preferred_bigs',\n",
      "       'pairing_requests_', 'on_off_campus_', 'has_car_', 'ideal_big_little',\n",
      "       'looking_for_ace', 'free_time', 'hobbies', 'favorite_artists_songs',\n",
      "       'icks', 'talk_for_hours_about', 'self_description', 'best_joke',\n",
      "       'favorite_food', 'earlybird_nightowl_', 'extroversion_', 'good_advice_',\n",
      "       'plans_style_', 'study_frequency_', 'gym_frequency_',\n",
      "       'spending_habits_', 'friday_night', 'additional_info_'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def clean_column_name(col):\n",
    "    # Remove parentheses and their contents\n",
    "    col = re.sub(r\"\\(.*?\\)\", \"\", col)\n",
    "    # Replace spaces and slashes with underscores\n",
    "    col = col.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    # Convert to lowercase and strip leading/trailing underscores\n",
    "    return col.strip().lower()\n",
    "\n",
    "main_df.columns = [clean_column_name(col) for col in main_df.columns]\n",
    "print(main_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c3fb99-df08-4b83-b2d4-276ce39444f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbinary_cols = ['on_off_campus_','has_car_']\\nmapping = {'On-Campus': 1, 'Off-Campus': 0, 'Yes': 1, 'No': 0}\\nfor col in binary_cols:\\n    binary_df[col] = binary_df[col].map(mapping)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitlering columns to convert\n",
    "\"\"\"\n",
    "binary_cols = ['on_off_campus_','has_car_']\n",
    "mapping = {'On-Campus': 1, 'Off-Campus': 0, 'Yes': 1, 'No': 0}\n",
    "for col in binary_cols:\n",
    "    binary_df[col] = binary_df[col].map(mapping)\n",
    "\"\"\"\n",
    "#print(main_df['on_off_campus_'], main_df['has_car_'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34213f7b-b726-490a-9237-a26cc713cf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name   pronouns           ufl_email              phone  \\\n",
      "0     Taylor Jarvis  they/them   daniel910@ufl.edu      (673)774-0860   \n",
      "1        Corey Knox    she/her  gabriel680@ufl.edu         1713894873   \n",
      "2        Mark Reyes  they/them    julie359@ufl.edu  (044)445-6922x353   \n",
      "3  Kathleen Ballard    she/her     tara913@ufl.edu       119.318.8215   \n",
      "4      Dawn Coleman  they/them   angela816@ufl.edu   931-155-4194x903   \n",
      "\n",
      "      socials other_orgs  role_  preferred_littles  preferred_bigs  \\\n",
      "0  @jeffrey63        VSO      1                NaN             2.0   \n",
      "1    @chris19        FSA      1                NaN             2.0   \n",
      "2    @tracy38        VSO      1                NaN             4.0   \n",
      "3    @james40        AAA      1                NaN             3.0   \n",
      "4   @joseph45        HSA      1                NaN             1.0   \n",
      "\n",
      "                pairing_requests_  ...  \\\n",
      "0                             NaN  ...   \n",
      "1                             NaN  ...   \n",
      "2                             NaN  ...   \n",
      "3         Prefer someone from AAA  ...   \n",
      "4  Prefer someone also into K-pop  ...   \n",
      "\n",
      "                          additional_info_  year_0 year_1 year_2  \\\n",
      "0  I love hanging out at Plaza of Americas       1      0      0   \n",
      "1  I love hanging out at Plaza of Americas       1      0      0   \n",
      "2                                      NaN       1      0      0   \n",
      "3                                      NaN       1      0      0   \n",
      "4                                      NaN       1      0      0   \n",
      "\n",
      "  major_Biology major_Computer Science major_Data Science major_Finance  \\\n",
      "0             0                      0                  0             1   \n",
      "1             0                      0                  0             0   \n",
      "2             0                      1                  0             0   \n",
      "3             0                      0                  0             1   \n",
      "4             0                      0                  1             0   \n",
      "\n",
      "  major_Marketing major_Mechanical Engineering  \n",
      "0               0                            0  \n",
      "1               0                            1  \n",
      "2               0                            0  \n",
      "3               0                            0  \n",
      "4               0                            0  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "## One Hot Encoding\n",
    "\"\"\"\n",
    " For categorical questions with a fixed number of mutually exclusive options (e.g., multiple choice)\n",
    " transforms a single column of categorical data into multiple new columns, one for each unique category. \n",
    " Each new column contains binary values (0 or 1) indicating the presence of that category\n",
    " Form Question Example: \n",
    "     What year are you? (Freshman, Sophomore, Junior, Senior)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Perform one hot encoding\n",
    "\n",
    "def one_hot_encode_columns(df, cols):\n",
    "    \"\"\"\n",
    "    Perform one-hot encoding on multiple categorical columns.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        cols (list[str]): List of column names to one-hot encode.    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with one-hot encoded columns added and original columns removed.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    df = df.copy()\n",
    "\n",
    "    # Perform one-hot encoding for the given columns\n",
    "    ohe_df = pd.get_dummies(df[cols], columns=cols, dtype=int)\n",
    "    \n",
    "    # Drop original columns since they are replaced by encoded ones\n",
    "    df = df.drop(columns=cols)\n",
    "    \n",
    "    # Join the encoded columns back\n",
    "    df = df.join(ohe_df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "OHE_columns = ['year', 'major']\n",
    "encoded_df = one_hot_encode_columns(df = main_df, cols = OHE_columns)\n",
    "print(encoded_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "028dcee4-f4c2-42ff-aa54-b7dd6e14e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from scipy.sparse import hstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c87eb814-17ba-4134-a1ea-f1a90308a707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TF-IDF Features ---\n",
      "   major_biology  major_computer  major_data  major_engineering  \\\n",
      "0            0.0         0.00000    0.000000           0.000000   \n",
      "1            0.0         0.00000    0.000000           0.707107   \n",
      "2            0.0         0.80703    0.000000           0.000000   \n",
      "3            0.0         0.00000    0.000000           0.000000   \n",
      "4            0.0         0.00000    0.793721           0.000000   \n",
      "\n",
      "   major_finance  major_marketing  major_mechanical  major_science  \\\n",
      "0            1.0              0.0          0.000000       0.000000   \n",
      "1            0.0              0.0          0.707107       0.000000   \n",
      "2            0.0              0.0          0.000000       0.590510   \n",
      "3            1.0              0.0          0.000000       0.000000   \n",
      "4            0.0              0.0          0.000000       0.608283   \n",
      "\n",
      "   other_orgs_aaa  other_orgs_csa  ...  friday_night_dinner  \\\n",
      "0             0.0             0.0  ...             0.000000   \n",
      "1             0.0             0.0  ...             0.000000   \n",
      "2             0.0             0.0  ...             0.000000   \n",
      "3             1.0             0.0  ...             0.000000   \n",
      "4             0.0             0.0  ...             0.707107   \n",
      "\n",
      "   friday_night_early  friday_night_friends  friday_night_gaming  \\\n",
      "0                 0.0              0.000000             0.795916   \n",
      "1                 0.0              0.000000             0.795916   \n",
      "2                 0.0              0.000000             0.795916   \n",
      "3                 0.0              0.000000             0.795916   \n",
      "4                 0.0              0.707107             0.000000   \n",
      "\n",
      "   friday_night_going  friday_night_marston  friday_night_movie  \\\n",
      "0                 0.0                   0.0                 0.0   \n",
      "1                 0.0                   0.0                 0.0   \n",
      "2                 0.0                   0.0                 0.0   \n",
      "3                 0.0                   0.0                 0.0   \n",
      "4                 0.0                   0.0                 0.0   \n",
      "\n",
      "   friday_night_night  friday_night_sleeping  friday_night_studying  \n",
      "0            0.605408                    0.0                    0.0  \n",
      "1            0.605408                    0.0                    0.0  \n",
      "2            0.605408                    0.0                    0.0  \n",
      "3            0.605408                    0.0                    0.0  \n",
      "4            0.000000                    0.0                    0.0  \n",
      "\n",
      "[5 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "## TF-IDF Vectorization\n",
    "\n",
    "def tf_idf_vectorization(df, col_names):\n",
    "    \"\"\"\n",
    "    Perform TF-IDF vectorization on multiple free-text columns.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        col_names (list[str]): List of text column names to vectorize.\n",
    "        return_df (bool): If True, returns a DataFrame with TF-IDF features. \n",
    "                          Otherwise, returns a sparse matrix for efficiency.\n",
    "    \n",
    "    Returns:\n",
    "        - scipy.sparse.csr_matrix if return_df=False\n",
    "        - pd.DataFrame if return_df=True\n",
    "    \"\"\"\n",
    "    tfidf_matrices = []\n",
    "    feature_names = []\n",
    "\n",
    "    # 1. Process each column independently\n",
    "    for col in col_names:\n",
    "        # Initialize TF-IDF vectorizer\n",
    "        vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        \n",
    "        # Fit and transform the column\n",
    "        tfidf_matrix = vectorizer.fit_transform(df[col].fillna(\"\"))\n",
    "        tfidf_matrices.append(tfidf_matrix)\n",
    "        \n",
    "        # Prefix feature names with the column name for clarity\n",
    "        col_feature_names = [f\"{col}_{feat}\" for feat in vectorizer.get_feature_names_out()]\n",
    "        feature_names.extend(col_feature_names)\n",
    "\n",
    "    # 2. Combine all TF-IDF matrices horizontally\n",
    "    combined_matrix = hstack(tfidf_matrices)\n",
    "\n",
    "    return combined_matrix, feature_names\n",
    "\n",
    "target_columns = ['major', 'other_orgs', 'free_time', 'hobbies','favorite_artists_songs', 'favorite_food', 'friday_night']\n",
    "tfidf_features, feature_names = tf_idf_vectorization(main_df, target_columns)\n",
    "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=feature_names)\n",
    "\n",
    "print(\"--- TF-IDF Features ---\")\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52d747d9-dd55-4b16-88e8-97607a80887f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/gstatsMCMC/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# S-BERT Embedding\n",
    "\"\"\"\n",
    "TLDR: Semantic Meaning, Context focused\n",
    "When: Open-ended where SEMANTIC MEANING, CONTEXT & NUANCE matters more than keywords\n",
    "    Good for personality, goals & abstractons\n",
    "What: BERT model using embeddings for texts, measured by cosine similarity\n",
    "Form Question Examples: \n",
    "    How would you describe your ideal big/little?,\n",
    "    What are you looking for when signing up for ACE?, \n",
    "    Describe yourself in your own words!\n",
    "\"\"\"\n",
    "# Documentation: https://sbert.net/index.html\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03e434cd-4358-4902-b64f-c896971b8d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████████████████████████████| 63/63 [00:01<00:00, 38.65it/s]\n",
      "Batches: 100%|██████████████████████████████████| 63/63 [00:00<00:00, 77.50it/s]\n",
      "Batches: 100%|██████████████████████████████████| 63/63 [00:00<00:00, 75.27it/s]\n",
      "Batches: 100%|██████████████████████████████████| 63/63 [00:00<00:00, 73.76it/s]\n",
      "Batches: 100%|██████████████████████████████████| 63/63 [00:01<00:00, 44.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of one embedding: (384,)\n",
      "First embedding vector: [-2.04107948e-02  4.95727584e-02  8.68641771e-03  3.78745385e-02\n",
      "  9.46523324e-02  8.24116543e-02  1.02947459e-01 -2.86993701e-02\n",
      " -1.24191813e-01  4.27318364e-02  4.27164137e-02 -4.55344319e-02\n",
      " -1.16479965e-02  1.67532228e-02 -3.85173061e-03 -2.18098797e-03\n",
      "  3.23110893e-02 -4.65100072e-02 -1.41100883e-02  6.01923242e-02\n",
      " -6.62544817e-02  4.87372354e-02  4.75156717e-02  4.03004885e-02\n",
      " -6.36311918e-02 -3.07687204e-02 -1.13959154e-02 -6.64756224e-02\n",
      "  1.14820688e-03 -2.85303574e-02 -1.22248940e-02 -3.33989933e-02\n",
      " -8.83906037e-02  9.34285820e-02  7.40805129e-03 -6.83075786e-02\n",
      "  3.30922082e-02  8.30406323e-02 -4.10827156e-03  6.20069131e-02\n",
      " -2.63682827e-02 -7.39176869e-02 -5.42335026e-03 -2.05392279e-02\n",
      "  2.99543366e-02  1.94231384e-02  5.45208156e-02 -1.80171654e-02\n",
      " -3.05588916e-02  2.62823105e-02  2.42399313e-02 -4.19275649e-02\n",
      " -3.35734636e-02  1.87906027e-02  2.09423173e-02 -4.85528968e-02\n",
      " -6.03714492e-03 -5.90868630e-02 -4.31731232e-02 -8.71142969e-02\n",
      " -5.50967567e-02 -2.00737501e-03 -3.07415854e-02  1.38948895e-02\n",
      "  3.56531069e-02  3.39535363e-02  3.04157473e-02 -3.28395851e-02\n",
      " -2.47145575e-02  1.80095956e-02  8.57502744e-02  2.18019332e-03\n",
      " -2.49578450e-02 -5.98004973e-03  4.32674633e-03  7.69839138e-02\n",
      "  5.40135205e-02  1.79085266e-02 -3.80577613e-03 -9.41821113e-02\n",
      "  4.31613103e-02  4.22799066e-02  6.27554813e-03 -6.47362769e-02\n",
      " -1.11375779e-01 -2.18612701e-03 -4.35536308e-03 -6.09127618e-02\n",
      " -5.27222939e-02 -1.25703169e-02 -7.65966438e-03 -1.20474759e-03\n",
      "  5.63319027e-02  5.70261069e-02 -2.55613700e-02  7.72622451e-02\n",
      " -6.08667498e-03 -4.30370197e-02 -1.01958171e-01  5.58632426e-02\n",
      " -1.85504891e-02 -1.86373256e-02 -6.82198405e-02 -1.91176012e-02\n",
      "  1.80801912e-03 -9.00188163e-02  2.54177451e-02 -9.51052606e-02\n",
      " -3.28371711e-02 -6.92085326e-02  3.43034007e-02 -4.14235555e-02\n",
      " -6.72401190e-02  5.26273716e-03  3.68951820e-02 -4.88627777e-02\n",
      "  1.15854079e-02 -2.32817680e-02  5.56135923e-02 -7.34092295e-02\n",
      "  3.81483994e-02  2.04084776e-02 -4.82274108e-02 -5.70729710e-02\n",
      "  3.37075219e-02 -1.03172697e-01 -6.34124801e-02 -7.48131946e-34\n",
      " -2.84927227e-02 -7.57447211e-03 -3.13078538e-02  1.03264697e-01\n",
      "  6.80669304e-03 -2.55040228e-02 -5.71565591e-02  1.89143848e-02\n",
      "  1.18251648e-02  7.86378458e-02 -7.46441782e-02  3.88700403e-02\n",
      " -2.74238810e-02  3.70955803e-02  6.50872593e-04 -4.18695249e-02\n",
      " -4.25162762e-02 -1.15860350e-01  5.96971214e-02 -6.00171089e-02\n",
      " -3.27650644e-02 -1.72486028e-03 -5.61465472e-02 -5.01142293e-02\n",
      " -6.32573888e-02  8.55848864e-02 -5.45807183e-02  2.06704140e-02\n",
      " -1.50598800e-02  4.81420346e-02 -1.30326767e-02  1.16603658e-01\n",
      " -1.44955851e-02 -7.14877679e-04  6.45346791e-02  7.51727372e-02\n",
      "  7.12878779e-02 -7.11232945e-02 -5.70104457e-03 -7.72867948e-02\n",
      " -2.87973136e-02  2.93771494e-02 -3.38269654e-03 -3.64975259e-02\n",
      "  1.08126834e-01  2.62444858e-02 -5.59019186e-02 -6.49084002e-02\n",
      " -1.64452922e-02  1.04049128e-02 -5.91090275e-03  8.91074389e-02\n",
      "  4.77826037e-02  3.26081691e-03  2.60337126e-02 -3.45789902e-02\n",
      " -5.11114486e-02  8.28865021e-02 -1.82809196e-02 -2.42526317e-03\n",
      "  7.66899511e-02 -3.30695100e-02 -6.34784177e-02 -2.84860823e-02\n",
      " -1.64620019e-02  1.81831513e-02  1.03558162e-02  2.28484496e-02\n",
      " -7.31076300e-03 -7.30120465e-02  1.87568199e-02  5.03442809e-02\n",
      " -5.71903884e-02  6.99845981e-03  1.77917350e-02  8.26803222e-03\n",
      "  5.23800589e-02 -1.63441747e-02  2.99164802e-02 -1.68801658e-02\n",
      "  1.35409134e-02  4.27305587e-02  7.24415332e-02  2.77411920e-04\n",
      "  7.21394569e-02 -7.98843950e-02  2.79668029e-02 -5.89110237e-03\n",
      "  6.85445815e-02 -5.42481691e-02 -6.34998903e-02  1.39219705e-02\n",
      "  8.86414424e-02  4.98579927e-02 -1.55532464e-01  2.42177826e-34\n",
      "  3.66138592e-02 -9.41484794e-02 -9.31693390e-02  1.13032363e-01\n",
      "  1.81216281e-02 -3.99752595e-02  3.36098634e-02 -7.32869375e-03\n",
      " -1.67850032e-02  1.21758245e-02  3.71844135e-02 -1.66833270e-02\n",
      "  5.19234277e-02  2.04196461e-02  1.28326818e-01 -4.97777052e-02\n",
      "  5.04818261e-02  3.10345739e-02  4.14584167e-02  4.18577269e-02\n",
      "  1.85399819e-02  4.55529382e-03 -1.23885192e-01 -1.27034290e-02\n",
      " -2.68773045e-02  3.71496491e-02  3.91126089e-02  8.48411210e-03\n",
      " -7.70791024e-02  2.60621253e-02  7.80890370e-03 -5.79950623e-02\n",
      "  1.58707537e-02  4.09433059e-02 -3.65699679e-02 -2.69289757e-03\n",
      "  7.05022812e-02  2.06873976e-02 -1.67299081e-02 -5.26015721e-02\n",
      "  6.14945665e-02 -4.55126949e-02 -6.03083521e-02 -3.80383362e-03\n",
      "  2.92672832e-02  1.88631639e-02 -1.28729232e-02  7.98598826e-02\n",
      " -4.43442352e-02  7.42828920e-02  2.44525801e-02 -1.59317944e-02\n",
      "  6.19633198e-02 -2.99000479e-02  3.78069431e-02 -9.59022716e-03\n",
      "  8.60575587e-02 -2.60448623e-02  2.28552558e-02  6.14840798e-02\n",
      " -9.14943032e-03  4.98271026e-02  3.17514455e-03 -5.77378646e-02\n",
      "  3.55368629e-02  4.08907197e-02 -5.73827289e-02  4.93986253e-03\n",
      "  2.83925235e-02 -1.05238147e-03 -2.36162636e-02 -2.69977413e-02\n",
      " -1.31192669e-01 -3.07412110e-02  9.47818533e-03  1.36884255e-03\n",
      "  9.19895247e-02  2.81060603e-03  2.19195876e-02  6.53559417e-02\n",
      " -3.35460193e-02 -1.15175284e-01 -4.57102507e-02  6.16945028e-02\n",
      "  9.71553177e-02  7.91152716e-02 -6.26244918e-02  2.25969334e-03\n",
      "  4.86206040e-02  2.53018867e-02 -1.44262528e-02 -4.65489216e-02\n",
      "  4.00111116e-02  1.88162271e-02 -1.29745966e-02 -1.77839716e-08\n",
      "  2.34318599e-02  3.33376229e-02  7.25536048e-02 -7.56221008e-04\n",
      "  1.33422278e-02  1.17791839e-01  3.37447934e-02 -1.43309087e-01\n",
      " -3.57736871e-02  4.35038954e-02 -8.43809918e-03  7.64773507e-03\n",
      "  3.63235921e-02  1.20349169e-01 -1.39708212e-02  4.15858477e-02\n",
      " -3.45840193e-02 -3.92311849e-02 -8.83526132e-02 -2.48588156e-02\n",
      " -4.60454151e-02  6.63310811e-02  4.10440825e-02 -1.48248719e-02\n",
      "  2.56466717e-02  3.51643488e-02 -2.34327838e-02  1.17007932e-02\n",
      " -2.64625009e-02  9.17121768e-02 -2.96680108e-02 -5.86999580e-03\n",
      " -9.21489671e-02 -1.08892620e-02  5.37302271e-02  5.42479195e-02\n",
      " -6.08987221e-03  2.18268633e-02  1.30026281e-01 -2.26376075e-02\n",
      " -3.52166258e-02  6.82926774e-02  7.21552670e-02 -2.25816816e-02\n",
      "  2.24365816e-02 -5.12835756e-02 -1.07763477e-01  3.31560010e-03\n",
      " -4.86237071e-02 -4.60692868e-03  2.75544412e-02 -7.91019294e-04\n",
      " -2.13108733e-02  5.05804494e-02  3.21894772e-02 -2.72422433e-02\n",
      "  6.81748986e-02  7.36418238e-04 -1.01815239e-02  5.96060753e-02\n",
      "  7.60559440e-02 -6.77764565e-02 -9.62626934e-03  3.39378044e-02]\n",
      "               name   pronouns           ufl_email              phone  \\\n",
      "0     Taylor Jarvis  they/them   daniel910@ufl.edu      (673)774-0860   \n",
      "1        Corey Knox    she/her  gabriel680@ufl.edu         1713894873   \n",
      "2        Mark Reyes  they/them    julie359@ufl.edu  (044)445-6922x353   \n",
      "3  Kathleen Ballard    she/her     tara913@ufl.edu       119.318.8215   \n",
      "4      Dawn Coleman  they/them   angela816@ufl.edu   931-155-4194x903   \n",
      "\n",
      "      socials  year                   major other_orgs  role_  \\\n",
      "0  @jeffrey63     0                 Finance        VSO      1   \n",
      "1    @chris19     0  Mechanical Engineering        FSA      1   \n",
      "2    @tracy38     0        Computer Science        VSO      1   \n",
      "3    @james40     0                 Finance        AAA      1   \n",
      "4   @joseph45     0            Data Science        HSA      1   \n",
      "\n",
      "   preferred_littles  ...  study_frequency_ gym_frequency_  spending_habits_  \\\n",
      "0                NaN  ...                 3              1                 3   \n",
      "1                NaN  ...                 4              2                 2   \n",
      "2                NaN  ...                 3              1                 5   \n",
      "3                NaN  ...                 3              1                 2   \n",
      "4                NaN  ...                 4              2                 1   \n",
      "\n",
      "          friday_night                         additional_info_  \\\n",
      "0     gaming all night  I love hanging out at Plaza of Americas   \n",
      "1     gaming all night  I love hanging out at Plaza of Americas   \n",
      "2     gaming all night                                      NaN   \n",
      "3     gaming all night                                      NaN   \n",
      "4  dinner with friends                                      NaN   \n",
      "\n",
      "                          ideal_big_little_embedding  \\\n",
      "0  [0.013327027, -0.086114444, -0.022169476, -0.0...   \n",
      "1  [0.013327027, -0.086114444, -0.022169476, -0.0...   \n",
      "2  [0.013327027, -0.086114444, -0.022169476, -0.0...   \n",
      "3  [-0.0061953766, -0.05777702, 0.03857713, 0.033...   \n",
      "4  [-0.034527037, -0.058441937, 0.011559242, 0.10...   \n",
      "\n",
      "                           looking_for_ace_embedding  \\\n",
      "0  [-0.019588161, -0.040873766, 0.049749676, 0.02...   \n",
      "1  [-0.09667426, 0.020778919, -0.01182306, 0.0177...   \n",
      "2  [-0.09667426, 0.020778919, -0.01182306, 0.0177...   \n",
      "3  [-0.019588161, -0.040873766, 0.049749676, 0.02...   \n",
      "4  [0.02646536, -0.01455135, -0.026929574, 0.0048...   \n",
      "\n",
      "                                      icks_embedding  \\\n",
      "0  [-0.008168175, -0.009438462, 0.01872369, 0.054...   \n",
      "1  [-0.005401648, 0.07903515, 0.075711645, 0.0159...   \n",
      "2  [-0.030117659, -0.021584412, -0.007534108, -0....   \n",
      "3  [-0.030117659, -0.021584412, -0.007534108, -0....   \n",
      "4  [-0.012263454, -0.012290109, 0.08721358, -0.01...   \n",
      "\n",
      "                      talk_for_hours_about_embedding  \\\n",
      "0  [-0.03987405, 0.022192685, 0.0034692998, 0.027...   \n",
      "1  [-0.016348138, -0.11628564, 0.00970566, 0.0105...   \n",
      "2  [-0.03987405, 0.022192685, 0.0034692998, 0.027...   \n",
      "3  [-0.03987405, 0.022192685, 0.0034692998, 0.027...   \n",
      "4  [0.056989856, 0.032094803, -0.022222444, -0.08...   \n",
      "\n",
      "                          self_description_embedding  \n",
      "0  [-0.020410795, 0.04957276, 0.008686418, 0.0378...  \n",
      "1  [0.0237088, 0.03708684, -0.03792438, -0.022004...  \n",
      "2  [-0.0785125, -0.091397375, 0.008947419, 0.0064...  \n",
      "3  [0.01942276, 0.0009503136, -0.001155221, 0.006...  \n",
      "4  [-0.03206001, 0.048228964, -0.021651598, -0.02...  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading pretrained model\n",
    "# More Models https://sbert.net/docs/sentence_transformer/pretrained_models.html \n",
    "BERT_PRETRAINED_MODEL = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "def sbert_embeddings(df, col_names, model_name=BERT_PRETRAINED_MODEL, batch_size=32):\n",
    "    \"\"\"\n",
    "    Generate Sentence-BERT embeddings for given text columns and append them to the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        col_names (list[str]): List of column names to encode.\n",
    "        model_name (str): Pretrained Sentence-BERT model. Default = \"all-MiniLM-L6-v2\".\n",
    "        batch_size (int): Batch size for encoding to improve performance. Default = 32.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with additional embedding columns.\n",
    "    \"\"\"\n",
    "    # Load the pretrained Sentence-BERT model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Create a copy to avoid modifying the original DataFrame\n",
    "    df = df.copy()\n",
    "\n",
    "    for col in col_names:\n",
    "        # Handle missing values\n",
    "        corpus = df[col].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "        # Encode column into embeddings\n",
    "        embeddings = model.encode(corpus, batch_size=batch_size, show_progress_bar=True)\n",
    "\n",
    "        # Convert embeddings to a list of numpy arrays\n",
    "        df[f\"{col}_embedding\"] = [np.array(emb) for emb in embeddings]\n",
    "\n",
    "    return df\n",
    "\n",
    "TARGET_COL_NAMES = ['ideal_big_little', 'looking_for_ace', 'icks', 'talk_for_hours_about', 'self_description']\n",
    "main_df = sbert_embeddings(main_df, TARGET_COL_NAMES)\n",
    "\n",
    "\n",
    "# Check the shape of one embedding\n",
    "print(\"Shape of one embedding:\", main_df[\"self_description_embedding\"][0].shape)\n",
    "\n",
    "# See the first embedding vector\n",
    "print(\"First embedding vector:\", main_df[\"self_description_embedding\"][0])\n",
    "\n",
    "# See the updated DataFrame\n",
    "print(main_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43ad2173-f042-4037-a98b-e7390e978e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63364114-f0e8-41f2-8a2a-572e10e0a14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Normalized Data ---\n",
      "0       0.666667\n",
      "1       0.333333\n",
      "2       0.333333\n",
      "3       0.666667\n",
      "4       0.000000\n",
      "          ...   \n",
      "1995    1.000000\n",
      "1996    1.000000\n",
      "1997    0.666667\n",
      "1998    0.333333\n",
      "1999    1.000000\n",
      "Name: extroversion_, Length: 2000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Normalized Numerical Features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_numerical_features(df, col_names, feature_range=(0, 1)):\n",
    "    \"\"\"\n",
    "    Normalize selected numerical columns in the DataFrame using MinMaxScaler.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        col_names (list[str]): List of numeric column names to normalize.\n",
    "        feature_range (tuple): Desired range of transformed data. Default = (0, 1).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with normalized columns.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid mutating original DataFrame\n",
    "    df = df.copy()\n",
    "\n",
    "    # Initialize MinMaxScaler\n",
    "    scaler = MinMaxScaler(feature_range=feature_range)\n",
    "\n",
    "    # Fit and transform the selected columns\n",
    "    df[col_names] = scaler.fit_transform(df[col_names])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Normalize selected numerical columns to range [0,1]\n",
    "norm_cols = [\"extroversion_\", \"good_advice_\", \"plans_style_\", \n",
    "             \"study_frequency_\", \"gym_frequency_\", \"spending_habits_\"]\n",
    "\n",
    "main_df = normalize_numerical_features(main_df, norm_cols)\n",
    "\n",
    "print(\"--- Normalized Data ---\")\n",
    "print(main_df[\"extroversion_\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f467d7e-2372-41c0-88f0-735fc4676836",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.to_csv('embedded_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d19d93-ccbc-406c-b27c-953a47294e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
