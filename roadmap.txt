Step 0 — Rename + clean columns

Apply your rename_map

Strip whitespace

Lowercase all categorical text

Convert numeric fields to integers/floats

Fill missing values

Step 1 — Preference Filtering Features

Not part of ML → used before scoring:

role
year
preferred_bigs / preferred_littles
pairing_requests
gender restrictions (if exist)
on_off_campus (optional rule)
has_car (optional rule)


These become hard filters or rule-based constraints.

Step 2 — Build Combined Text Profile
Raw fields:
free_time
hobbies
self_description
icks
talk_for_hours_about
friday_night
additional_info
favorite_food (optional)
favorite_artists_songs (optional)
best_joke (optional, but funny)

Combined:
profile_text = (
    f"{free_time}. {hobbies}. {self_description}. {icks}. "
    f"{talk_for_hours_about}. {friday_night}. {additional_info}."
)

Build SBERT embedding:
profile_embedding: 768 dimensions

Step 3 — Categorical Features

Categorical → one-hot encode → small vectors (5–40 dims)

major
earlybird_nightowl
on_off_campus
has_car
looking_for_ace


You may also embed “major” using a learnable embedding layer:

20–50 academic majors → embed to 16 dims

Step 4 — Numeric Likert Features

Normalize using StandardScaler:

extroversion
good_advice
plans_style
study_frequency
gym_frequency
spending_habits


These become a 6-dim numeric vector.

Step 5 — Construct Final ML Feature Vector
Before Tower (input features):
[
  profile_embedding (768),
  categorical_vector (~20),
  numeric_vector (6)
]


Expected dimension: ~800 total.

Step 6 — Two-Tower Architecture

Mentor Tower → 128 dim
Mentee Tower → 128 dim

Both L2-normalized.

Step 7 — Similarity Scoring

Use:

dot product

cosine similarity

Faiss index (HNSW or Flat)

Return top-5 nearest mentors for each mentee.

Step 8 — Post-processing

Apply soft constraints:

year difference weighting

major similarity bonus

shared interests

availability

Step 9 — Final Ranking Algorithm

Combined score:

score = α * ml_similarity + β * preference_score + γ * year_bonus + δ * major_match


Then pick top-5 or run stable matching.