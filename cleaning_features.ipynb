{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50a4e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "781b0d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 33 columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Pronouns', 'UFL Email', 'Phone', 'Socials', 'Year', 'Major',\n",
       "       'Other Orgs', 'Role (0=Big,1=Little)', 'Preferred Littles',\n",
       "       'Preferred Bigs', 'Pairing Requests (Optional)',\n",
       "       'On/Off Campus (0=On,1=Off)', 'Has Car (0=No,1=Yes)',\n",
       "       'Ideal Big/Little', 'Looking For ACE', 'Free Time', 'Hobbies',\n",
       "       'Favorite Artists/Songs', 'Icks', 'Talk for Hours About',\n",
       "       'Self Description', 'Best Joke', 'Favorite Food',\n",
       "       'EarlyBird/NightOwl (0=Early,1=Night)', 'Extroversion (1-5)',\n",
       "       'Good Advice (1-5)', 'Plans Style (1-5)', 'Study Frequency (1-5)',\n",
       "       'Gym Frequency (1-5)', 'Spending Habits (1-5)', 'Friday Night',\n",
       "       'Additional Info (Optional)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/vso_ratataou_ace_mock_data.csv\")\n",
    "\n",
    "print(f\"There are {len(df.columns)} columns\")\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c2258be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'pronouns', 'ufl_email', 'phone', 'socials', 'year', 'major',\n",
       "       'other_orgs', 'role', 'preferred_littles', 'preferred_bigs',\n",
       "       'pairing_requests', 'on_off_campus', 'has_car', 'ideal_big_little',\n",
       "       'looking_for_ace', 'free_time', 'hobbies', 'favorite_artists_songs',\n",
       "       'dislikes', 'talk_for_hours_about', 'self_description', 'best_joke',\n",
       "       'favorite_food', 'earlybird_nightowl', 'extroversion', 'good_advice',\n",
       "       'plans_style', 'study_frequency', 'gym_frequency', 'spending_habits',\n",
       "       'friday_night', 'additional_info'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_map = {\n",
    "    'Name': 'name',\n",
    "    'Pronouns': 'pronouns',\n",
    "    'UFL Email': 'ufl_email',\n",
    "    'Phone': 'phone',\n",
    "    'Socials': 'socials',\n",
    "    'Year': 'year',\n",
    "    'Major': 'major',\n",
    "    'Other Orgs': 'other_orgs',\n",
    "    'Role (0=Big,1=Little)': 'role',\n",
    "    'Preferred Littles': 'preferred_littles',\n",
    "    'Preferred Bigs': 'preferred_bigs',\n",
    "    'Pairing Requests (Optional)': 'pairing_requests',\n",
    "    'On/Off Campus (0=On,1=Off)': 'on_off_campus',\n",
    "    'Has Car (0=No,1=Yes)': 'has_car',\n",
    "    'Ideal Big/Little': 'ideal_big_little',\n",
    "    'Looking For ACE': 'looking_for_ace',\n",
    "    'Free Time': 'free_time',\n",
    "    'Hobbies': 'hobbies',\n",
    "    'Favorite Artists/Songs': 'favorite_artists_songs',\n",
    "    'Icks': 'dislikes',\n",
    "    'Talk for Hours About': 'talk_for_hours_about',\n",
    "    'Self Description': 'self_description',\n",
    "    'Best Joke': 'best_joke',\n",
    "    'Favorite Food': 'favorite_food',\n",
    "    'EarlyBird/NightOwl (0=Early,1=Night)': 'earlybird_nightowl',\n",
    "    'Extroversion (1-5)': 'extroversion',\n",
    "    'Good Advice (1-5)': 'good_advice',\n",
    "    'Plans Style (1-5)': 'plans_style',\n",
    "    'Study Frequency (1-5)': 'study_frequency',\n",
    "    'Gym Frequency (1-5)': 'gym_frequency',\n",
    "    'Spending Habits (1-5)': 'spending_habits',\n",
    "    'Friday Night': 'friday_night',\n",
    "    'Additional Info (Optional)': 'additional_info'\n",
    "}\n",
    "df = df.rename(columns=rename_map)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1d895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Name\n",
    "UFL_Email\n",
    "\n",
    "# Preference Filtering characteristics\n",
    "hard:\n",
    "Big/Little\n",
    "Do Not Pair with\n",
    "\n",
    "soft -- boost:\n",
    "Major\n",
    "Year difference\n",
    "Org participation\n",
    "\n",
    "# Feature Engineering -> Sentence-BERT\n",
    "## Text Features\n",
    "Free Time \n",
    "Hobbies\n",
    "Self Description\n",
    "dislikes\n",
    "Talk for Hours About\n",
    "Friday Night\n",
    "\n",
    "## Categorical Features -> Embedding_Layer / One Hot\n",
    "Major\n",
    "EarlyBord/NightOwl\n",
    "\n",
    "## Numerial Features -> Normalized 0-1\n",
    "Extroversion\n",
    "Good Advice\n",
    "Plans Style\n",
    "Study Frequency\n",
    "Gym Frequency\n",
    "Spending Habits\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a605abdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147.4313399518569"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling Duplicate entries by ufl_email -- keeping the latest entry\n",
    "## Reoders dataframe by index, keep the last entry and drop everything else\n",
    "df_cleaned = df.sort_index().drop_duplicates(subset=[\"ufl_email\"], keep=\"last\")\n",
    "\n",
    "# Handling Empty Fields\n",
    "df_cleaned = df_cleaned.fillna(np.NaN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b9a21",
   "metadata": {},
   "source": [
    "# Normalizing Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45daa33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(dataframe: pd.DataFrame, columns: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize data to a 0-1 range\n",
    "\n",
    "    Args:\n",
    "        dataframe: a pandas DataFrame\n",
    "        columns: column names to be normalized\n",
    "\n",
    "    Return the dataframe with normalized columns\n",
    "    \"\"\"\n",
    "    \n",
    "    df_out = dataframe.copy() # could remove this to modify in-place\n",
    "    for col in columns:\n",
    "        xmin = df_out[col].min()\n",
    "        xmax = df_out[col].max()\n",
    "        df_out[col] = (df_out[col] - xmin) / (xmax - xmin)\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "### This is how we normalize data! OR We could use sklearn.preprocessing MinMaxScaler\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "141fd7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.666667\n",
       "1       0.333333\n",
       "2       0.333333\n",
       "3       0.666667\n",
       "4       0.000000\n",
       "          ...   \n",
       "1995    1.000000\n",
       "1996    1.000000\n",
       "1997    0.666667\n",
       "1998    0.333333\n",
       "1999    1.000000\n",
       "Name: extroversion, Length: 1987, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "columns_to_scale = ['extroversion', 'good_advice', 'plans_style', 'study_frequency', 'gym_frequency', 'spending_habits']\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_cleaned[columns_to_scale] = scaler.fit_transform(df_cleaned[columns_to_scale])\n",
    "\n",
    "df_cleaned['extroversion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b8bfd9",
   "metadata": {},
   "source": [
    "# Text Features -> One single Sentence-SBERT Embedding\n",
    "\n",
    "Why do we combine them into one single Embedding?\n",
    "1. Many embeddings leads to noisier signal, and larger dimensions to work with\n",
    "\n",
    "2. Multiple embedding lose cross context, where it only sees local patterns, and misses global patterns.\n",
    "\n",
    "3. SBERT is trained on semantic similarity, and large conherent text\n",
    "\n",
    "4. N text fields x 768  > 1 text field x 768 -- Model is faster with smaller embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac3fa0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       photography.traveling, music, movies.Ahead ten...\n",
       "1       photography.music, reading.Defense stage fall ...\n",
       "2       cooking.gaming.Seven hand across anything also...\n",
       "3       traveling.traveling, photography.Situation dri...\n",
       "4       cooking.gym, photography.Crime area strategy b...\n",
       "                              ...                        \n",
       "1995    gym.gym, movies, music.It explain response mat...\n",
       "1996    traveling.photography, traveling.Song hear exe...\n",
       "1997    movies.gaming.Often usually though fire succes...\n",
       "1998    movies.cooking, movies, photography.Range beha...\n",
       "1999    photography.traveling, reading, gaming.People ...\n",
       "Name: profile_text, Length: 1987, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_col_combine = ['free_time', 'hobbies', 'self_description', 'dislikes', 'talk_for_hours_about', 'friday_night', 'additional_info']\n",
    "\n",
    "# 1. For each column 2. fill NaN with an empty string 3. convert to str 4. join each row with comma as delimiter\n",
    "df_cleaned['profile_text'] = df_cleaned[text_col_combine].fillna('').astype(str).apply('.'.join, axis=1)\n",
    "df_cleaned['profile_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa7d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gstatsmcmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
